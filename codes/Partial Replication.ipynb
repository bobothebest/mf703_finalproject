{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta as rd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks data csv read\n",
    "df = pd.read_csv('/Users/apple/Downloads/data.csv')\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# s&p data csv read\n",
    "df_sp = pd.read_csv('/Users/apple/Downloads/sp500.csv')\n",
    "df_sp = df_sp.set_index('Date')\n",
    "\n",
    "# stocks data csv read for partial replication\n",
    "df_reduce = pd.read_csv('/Users/apple/Downloads/data.csv')\n",
    "df_reduce = df_reduce.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385, 471)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385, 471)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_slicer(df, start, duration, rebalancing_period=0):\n",
    "    '''\n",
    "    this function is used to slice out specific section of the data\n",
    "    '''\n",
    "    start = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=rebalancing_period))\n",
    "    end = str(datetime.strptime(start, '%Y-%m-%d').date() + rd(months=duration) - rd(days=1))\n",
    "    return df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    '''\n",
    "    this function gets the dataframe as input, processes it, and ouputs the cumulative change of the stocks\n",
    "    that is used as input for training the model.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    df = df.to_numpy()\n",
    "    df = torch.from_numpy(df).type(torch.Tensor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_change(df):\n",
    "    '''\n",
    "    this function calculate the daily change of stocks included in the dataframe.\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(df):\n",
    "    '''\n",
    "    this function calculate the daily return of stocks included in the dataframe, note that \n",
    "    daily return is equal to daily change + 1\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_finder(df):\n",
    "    '''\n",
    "    this function is just being used for extracting the stocks symbols\n",
    "    '''\n",
    "    df = df.pct_change()\n",
    "    df = df.tail(-1)\n",
    "    df = df + 1\n",
    "    df = df.cumprod()\n",
    "    df = df - 1\n",
    "    df = df.iloc[-1,:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing stocks symbols\n",
    "stocks_index = index_finder(df).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf biuld\n",
    "class shallow_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Shallow NNF model, consisted of 2 fully connected layers, \n",
    "    a relU activation function in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shallow nnf partial biuld which is the same as original shallow nnf\n",
    "this class helps us to use the full replication training to find the best companies to invest\n",
    "and then find the optimal wieghts with the partial model\n",
    "'''\n",
    "class shallow_NNF_partial(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(shallow_NNF_partial, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.softmax(self.fc2(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalancing period = one or three months\n",
    "rbp = 1\n",
    "\n",
    "# number of companies in the partial portfolio\n",
    "partial_num = 50\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size = 471\n",
    "num_classes = 471\n",
    "lr = 1e-3 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF = shallow_NNF(input_dim=input_dim, hidden_size=hidden_size, num_classes=num_classes)\n",
    "shallow_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_optimizer = torch.optim.Adam(shallow_NNF.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf partial tune\n",
    "'''\n",
    "loss function is set to MSE and Adam optimizer is used in this model.\n",
    "'''\n",
    "shallow_NNF_partial = shallow_NNF_partial(input_dim=partial_num, hidden_size=hidden_size, num_classes=partial_num)\n",
    "shallow_NNF_partial_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "shallow_NNF_partial_optimizer = torch.optim.Adam(shallow_NNF_partial.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def RMSE(x, y, weights):\n",
    "    '''\n",
    "    this function calculates the root mean squere error of constructed portfollio and benchmark index \n",
    "    that is used for evaluating trained models.\n",
    "    '''\n",
    "    temp = 0\n",
    "    for i in range(len(x)):\n",
    "        temp += (sum(x.iloc[i] * weights) - y.iloc[i]) ** 2\n",
    "    return math.sqrt(temp/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN\n",
    "def MEAN(x, weights):\n",
    "    '''\n",
    "    this function calculates the mean return of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "def VOL(x, weights):\n",
    "    '''\n",
    "    this function calculates the volatility of the constructed portfolio during the given period.\n",
    "    '''\n",
    "    temp = []\n",
    "    for i in range(len(x)):\n",
    "        temp.append(sum(x.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(df, x_test, model, i, temp):   \n",
    "    '''\n",
    "    this function outputs the cumulative return of the portfolio test dataset of the given dataframe\n",
    "    ''' \n",
    "    x_return = date_slicer(df, '2018-01-01', 1, i)\n",
    "    x_return =  x_return.pct_change()\n",
    "    x_return =  x_return.tail(-1)\n",
    "    x_return =  x_return + 1\n",
    "    x_return =  x_return.cumprod()\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    for i in range(len(x_return)):\n",
    "        temp.append(sum(x_return.iloc[i] * weights))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_return(df_sp, i, temp):\n",
    "    '''\n",
    "    this function outputs the cumulative return of the benchmark index test dataset of the given dataframe\n",
    "    '''\n",
    "    y_return = date_slicer(df_sp, '2018-01-01', 1, i)\n",
    "    y_return = y_return.pct_change()\n",
    "    y_return = y_return.tail(-1)\n",
    "    y_return = y_return + 1\n",
    "    y_return = y_return.cumprod()\n",
    "    \n",
    "    for i in range(len(y_return)):\n",
    "        temp.append(sum(y_return.iloc[i]))\n",
    "    temp = np.array(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fun(x_valid, i, model):\n",
    "    '''\n",
    "    this function gets validation dataset, model and rebalaning period as input, then outputs the RMSE of given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2017-07-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    # x_return = daily_return(date_slicer(df, '2017-07-01', 6, i))\n",
    "    # y_return = daily_return(date_slicer(df_sp, '2017-07-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_valid).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_valid)[1].detach())\n",
    "    \n",
    "    valid_rmse = RMSE(x_change, y_change, weights)\n",
    "    # valid_mean = MEAN(x_return, weights)\n",
    "    # valid_vol  = VOL(x_return, weights)\n",
    "    \n",
    "    print(f'Validation RMSE: {valid_rmse}')\n",
    "    # print(f'Validation MEAN: {valid_mean}')\n",
    "    # print(f'Validation VOL: {valid_vol}')\n",
    "    \n",
    "    return valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(x_test, i, model):\n",
    "    '''\n",
    "    this function gets test dataset, model and rebalaning period as input, then outputs the RMSE, Mean and volatility \n",
    "    of the given dataset.\n",
    "    '''\n",
    "    x_change = daily_change(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_change = daily_change(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    x_return = daily_return(date_slicer(df_reduce, '2018-01-01', 6, i))\n",
    "    y_return = daily_return(date_slicer(df_sp, '2018-01-01', 6, i))\n",
    "    \n",
    "    if model == equal_w_model:\n",
    "        weights = model(x_test).performance()[1]\n",
    "    else:\n",
    "        weights = np.array(model(x_test)[1].detach())\n",
    "    \n",
    "    test_rmse = RMSE(x_change, y_change, weights)\n",
    "    test_mean = MEAN(x_return, weights)\n",
    "    test_vol  = VOL(x_return, weights)\n",
    "    test_dic = {'RMSE': test_rmse, 'MEAN': test_mean, 'VOL': test_vol}\n",
    "    \n",
    "    print(f'Test RMSE: {test_rmse}')\n",
    "    print(f'Test MEAN: {test_mean}')\n",
    "    print(f'Test VOL: {test_vol}')\n",
    "    \n",
    "    return test_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf build\n",
    "class deep_NNF(nn.Module):\n",
    "    '''\n",
    "    this class is used to train the data with Deep NNF model, consisted of 6 fully connected layers, \n",
    "    relU activation functions in between and a softmax layer output that is translated into stock weights in portfolio.\n",
    "    dropout is also included in deep NNF model.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_size1, hidden_size2, hidden_size3,\n",
    "                 hidden_size4, hidden_size5, num_classes, dropout_p = 0.2):\n",
    "        super(deep_NNF, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size1) # fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2) # fully connected layer\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3) # fully connected layer\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4) # fully connected layer\n",
    "        self.fc5 = nn.Linear(hidden_size4, hidden_size5) # fully connected layer\n",
    "        self.fc6 = nn.Linear(hidden_size5, num_classes) # fully connected layer\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        self.fc6.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc3(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc4(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc5(out))\n",
    "        out = self.softmax(self.fc6(out))\n",
    "        weights = out\n",
    "        cumulative_change = sum(out * x)\n",
    "        return cumulative_change, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_nnf hyperparameters\n",
    "input_dim = 471\n",
    "hidden_size1 = 471\n",
    "hidden_size2 = 471\n",
    "hidden_size3 = 471\n",
    "hidden_size4 = 471\n",
    "hidden_size5 = 471\n",
    "num_classes = 471\n",
    "lr = 1e-7 # learning rate\n",
    "# probability of a neuron being shutdown that shuffles every epoch minimizing the overfit phenomenon\n",
    "dropout_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep nnf tune\n",
    "'''\n",
    "like in shallow NNF, loss function is set to MSE and Adam optimizer is used.\n",
    "'''\n",
    "deep_NNF = deep_NNF(input_dim=input_dim, hidden_size1=hidden_size1, hidden_size2=hidden_size2, \n",
    "                    hidden_size3=hidden_size3, hidden_size4=hidden_size4, hidden_size5=hidden_size5,\n",
    "                    num_classes=num_classes)\n",
    "deep_NNF_loss_fun = torch.nn.MSELoss(reduction='mean')\n",
    "deep_NNF_optimizer = torch.optim.Adam(deep_NNF.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num):\n",
    "    df_partial = pd.DataFrame({'x_train': x_train, 'x_valid': x_valid, 'x_test': x_test,\n",
    "                               'weights': weights}, index = stocks_index)\n",
    "    df_partial = df_partial.sort_values(by = ['weights'])\n",
    "    out_index = df_partial.index[num:]\n",
    "    df_partial = df_partial.iloc[:num]\n",
    "    \n",
    "    x_train = df_partial['x_train'].to_numpy()\n",
    "    x_valid = df_partial['x_valid'].to_numpy()\n",
    "    x_test = df_partial['x_test'].to_numpy()\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_valid = torch.from_numpy(x_valid).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    \n",
    "    return x_train, x_valid, x_test, out_index\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shallow NNF Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf training function\n",
    "def train_shallow_nnf(x_train, y_train, i):\n",
    "    '''\n",
    "    this function is used to train the model using x_train & y_train given to it, printing MSE of trained model in first and last\n",
    "    epoch and also printing train time of the model\n",
    "    '''\n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nShallow NNF Training & Results for model {(i/rbp)+1}:')\n",
    "    print(\"x_train.shape\")\n",
    "    print(x_train.shape)\n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            weights = np.array(deep_NNF(x_train)[1].detach())\n",
    "            \n",
    "            print(\"weights\")\n",
    "            print(\"deep_NNF(x_train)[1].shape\")\n",
    "            print(deep_NNF(x_train)[1].shape)\n",
    "\n",
    "            print(\"deep_NNF(x_train)[0].shape\")\n",
    "            print(deep_NNF(x_train)[0].shape)\n",
    "            \n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow nnf partial training function\n",
    "def train_shallow_nnf_partial(x_train, y_train, i):    \n",
    "    start_time_shallow_nnf = time.time()\n",
    "    print(f'\\nDeep NNF Training & Results for model {(i/rbp)+1} (Partial replication):')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_train_pred = shallow_NNF_partial(x_train)[0]\n",
    "        loss_shallow_nnf = shallow_NNF_partial_loss_fun(y_train_pred, y_train)\n",
    "        if epoch == 0 or epoch == num_epochs-1:\n",
    "            print(f'Epoch {epoch+1} of {num_epochs} | MSE: {loss_shallow_nnf.item()}')\n",
    "        shallow_NNF_partial_optimizer.zero_grad()\n",
    "        loss_shallow_nnf.backward()\n",
    "        shallow_NNF_partial_optimizer.step()\n",
    "        \n",
    "    training_time = format(time.time()-start_time_shallow_nnf, '0.2f')\n",
    "    print(f'Training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 1.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.04368942603468895\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.7945667174501523e-10\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 1.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.11405888944864273\n",
      "Epoch 100 of 100 | MSE: 9.18633134006086e-08\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0021850764032716003\n",
      "Test RMSE: 0.0020699087341954567\n",
      "Test MEAN: 1.0002930009802125\n",
      "Test VOL: 0.009512322622623656\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 2.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.056767601519823074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/ryqgqp6n03schy65y0b0g4sm0000gn/T/ipykernel_24518/1184317780.py:10: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return math.sqrt(temp/len(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.0231136826632792e-08\n",
      "Training time: 0.40\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 2.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.10646946728229523\n",
      "Epoch 100 of 100 | MSE: 5.034713979057415e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002371994551996431\n",
      "Test RMSE: 0.002482867513463893\n",
      "Test MEAN: 1.0000678601854107\n",
      "Test VOL: 0.009496709513081477\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 3.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.0436181016266346\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 9.833725198404863e-05\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 3.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.09441396594047546\n",
      "Epoch 100 of 100 | MSE: 9.798705846719713e-09\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0021582457677304773\n",
      "Test RMSE: 0.002300756508492957\n",
      "Test MEAN: 1.00065438300361\n",
      "Test VOL: 0.007194854513949797\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 4.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.06094898283481598\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.389993485645391e-06\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 4.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.05920828506350517\n",
      "Epoch 100 of 100 | MSE: 2.3675788440868928e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0020831071426795638\n",
      "Test RMSE: 0.002390588831374541\n",
      "Test MEAN: 1.001060642931387\n",
      "Test VOL: 0.005798832533037819\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 5.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.04554818570613861\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 7.295458459566362e-09\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 5.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.0332336500287056\n",
      "Epoch 100 of 100 | MSE: 1.760781742632389e-09\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0023010594319272217\n",
      "Test RMSE: 0.0025482251983717998\n",
      "Test MEAN: 1.0000972906468228\n",
      "Test VOL: 0.007179935930765787\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 6.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.05097443237900734\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.1441736447181938e-09\n",
      "Training time: 0.40\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 6.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.05489172041416168\n",
      "Epoch 100 of 100 | MSE: 2.4619347982479667e-07\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.002073739120894208\n",
      "Test RMSE: 0.002592079196132033\n",
      "Test MEAN: 1.0001110080661992\n",
      "Test VOL: 0.007671920921889761\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 7.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.04016627371311188\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 7.685654964006972e-06\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 7.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.057831551879644394\n",
      "Epoch 100 of 100 | MSE: 1.8759047293315234e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0020932197081065624\n",
      "Test RMSE: 0.002693157358651831\n",
      "Test MEAN: 0.9992771127627276\n",
      "Test VOL: 0.010563336035704834\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 8.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.03870237246155739\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 7.839809690324273e-09\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 8.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.03446835279464722\n",
      "Epoch 100 of 100 | MSE: 2.3987598751773476e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0023469151685538807\n",
      "Test RMSE: 0.0029175491218248343\n",
      "Test MEAN: 0.9998126607709399\n",
      "Test VOL: 0.011173358714436346\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 9.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.02921021729707718\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 8.97720965440385e-05\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 9.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.05728607997298241\n",
      "Epoch 100 of 100 | MSE: 3.0210878776415484e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.00228206499820175\n",
      "Test RMSE: 0.0028172257671308007\n",
      "Test MEAN: 0.9998268272007181\n",
      "Test VOL: 0.01152476803567481\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 10.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.02843138389289379\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 9.656559268478304e-05\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 10.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.06138774752616882\n",
      "Epoch 100 of 100 | MSE: 7.931655332527043e-10\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.0018906026270593562\n",
      "Test RMSE: 0.002871590158117754\n",
      "Test MEAN: 0.9998054345448575\n",
      "Test VOL: 0.011742002194091697\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 11.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.03950589522719383\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 5.671666691853261e-09\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 11.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.04177875071763992\n",
      "Epoch 100 of 100 | MSE: 1.7204968116857344e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002637983601490527\n",
      "Test RMSE: 0.0028366130275740216\n",
      "Test MEAN: 1.0007782208519438\n",
      "Test VOL: 0.010356993321753537\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 12.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.033413875848054886\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.2108238479413558e-05\n",
      "Training time: 0.41\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 12.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.05720791220664978\n",
      "Epoch 100 of 100 | MSE: 1.374488078909053e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0027025944863881294\n",
      "Test RMSE: 0.0024893486290535082\n",
      "Test MEAN: 1.0000149072445217\n",
      "Test VOL: 0.010245889237163748\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 13.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.03563261404633522\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 6.326993151617444e-09\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 13.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.1518688052892685\n",
      "Epoch 100 of 100 | MSE: 1.0663669947064136e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0027144480558971267\n",
      "Test RMSE: 0.0024070081996951536\n",
      "Test MEAN: 1.0016497400801403\n",
      "Test VOL: 0.00824539451776494\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 14.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.03258848190307617\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.3208145901444368e-06\n",
      "Training time: 0.40\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 14.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.05585109442472458\n",
      "Epoch 100 of 100 | MSE: 3.1065354733073036e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0025998211757408225\n",
      "Test RMSE: 0.002433013761362682\n",
      "Test MEAN: 1.0006062737879289\n",
      "Test VOL: 0.0069810077911151925\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 15.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.029984908178448677\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 9.258735644834815e-08\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 15.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.01670839451253414\n",
      "Epoch 100 of 100 | MSE: 1.46293245961715e-07\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.0026383311516526547\n",
      "Test RMSE: 0.0022485531806503345\n",
      "Test MEAN: 1.000466494363104\n",
      "Test VOL: 0.008748019206812752\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 16.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.030989114195108414\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.7550230495544383e-06\n",
      "Training time: 0.41\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 16.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.03287845849990845\n",
      "Epoch 100 of 100 | MSE: 2.0048014448548201e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0029378401103149925\n",
      "Test RMSE: 0.002464137471415092\n",
      "Test MEAN: 1.000363260393121\n",
      "Test VOL: 0.008767219942350017\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 17.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.02717169001698494\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 2.298389745192253e-08\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 17.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.048292048275470734\n",
      "Epoch 100 of 100 | MSE: 3.3461952853031107e-07\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002622646371081663\n",
      "Test RMSE: 0.0021797262126609204\n",
      "Test MEAN: 1.0003332411391828\n",
      "Test VOL: 0.009189911265370124\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 18.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.021242259070277214\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 7.32093585753546e-09\n",
      "Training time: 0.38\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 18.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.04044291004538536\n",
      "Epoch 100 of 100 | MSE: 7.750347918999978e-09\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0023539088820406697\n",
      "Test RMSE: 0.002085070595802016\n",
      "Test MEAN: 1.000922814165533\n",
      "Test VOL: 0.00829217662880492\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 19.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.018122278153896332\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.2875972288384219e-08\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 19.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.023779746145009995\n",
      "Epoch 100 of 100 | MSE: 5.08297626211629e-10\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0026581904767172394\n",
      "Test RMSE: 0.0021179377980019244\n",
      "Test MEAN: 1.0005300127626278\n",
      "Test VOL: 0.008351288397786804\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 20.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.042130131274461746\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 3.5700864486898354e-10\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 20.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.04685310646891594\n",
      "Epoch 100 of 100 | MSE: 4.522826202446595e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.002762460928120508\n",
      "Test RMSE: 0.002229378208896507\n",
      "Test MEAN: 1.000700825221784\n",
      "Test VOL: 0.008977211337340312\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 21.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.03928513824939728\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 1.2947995742251805e-07\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 21.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.018088437616825104\n",
      "Epoch 100 of 100 | MSE: 2.299674122241413e-07\n",
      "Training time: 0.05\n",
      "Validation RMSE: 0.0022685224796842375\n",
      "Test RMSE: 0.002158893999239278\n",
      "Test MEAN: 1.0008771006040467\n",
      "Test VOL: 0.006125719430803616\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 22.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.02445709891617298\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 8.138138163360509e-09\n",
      "Training time: 0.40\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 22.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.02322499267756939\n",
      "Epoch 100 of 100 | MSE: 2.1806340555485804e-07\n",
      "Training time: 0.07\n",
      "Validation RMSE: 0.0025991608656421666\n",
      "Test RMSE: 0.002733849967198511\n",
      "Test MEAN: 1.001250683142829\n",
      "Test VOL: 0.006590323018963805\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 23.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.02794797718524933\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 3.1560105639982794e-08\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 23.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.027699777856469154\n",
      "Epoch 100 of 100 | MSE: 2.6110743789331536e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0024994893548665143\n",
      "Test RMSE: 0.001960903424900591\n",
      "Test MEAN: 1.0007947588709776\n",
      "Test VOL: 0.004719771602079246\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "y_train.shape\n",
      "torch.Size([1])\n",
      "x_valid.shape\n",
      "torch.Size([471])\n",
      "y_valid.shape\n",
      "torch.Size([1])\n",
      "x_test.shape\n",
      "torch.Size([471])\n",
      "y_test.shape\n",
      "torch.Size([1])\n",
      "\n",
      "Shallow NNF Training & Results for model 24.0:\n",
      "x_train.shape\n",
      "torch.Size([471])\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 1 of 100 | MSE: 0.017776791006326675\n",
      "weights\n",
      "deep_NNF(x_train)[1].shape\n",
      "torch.Size([471])\n",
      "deep_NNF(x_train)[0].shape\n",
      "torch.Size([])\n",
      "Epoch 100 of 100 | MSE: 4.404455822282216e-08\n",
      "Training time: 0.39\n",
      "weights.shape:\n",
      "(471,)\n",
      "\n",
      "Deep NNF Training & Results for model 24.0 (Partial replication):\n",
      "Epoch 1 of 100 | MSE: 0.015126990154385567\n",
      "Epoch 100 of 100 | MSE: 1.9528130223989137e-08\n",
      "Training time: 0.06\n",
      "Validation RMSE: 0.0020956446564667553\n",
      "Test RMSE: 0.0016722839962273783\n",
      "Test MEAN: 1.0016705527319685\n",
      "Test VOL: 0.004871807217650528\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'deep_best_result_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     shallow_NNF_partial\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelected Model Test Results for model i =\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[43mdeep_best_result_index\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mare: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE =\u001b[39m\u001b[38;5;124m'\u001b[39m, shallow_nnf_test_results[(deep_best_result_index)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN =\u001b[39m\u001b[38;5;124m'\u001b[39m, shallow_nnf_test_results[(deep_best_result_index)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEAN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deep_best_result_index' is not defined"
     ]
    }
   ],
   "source": [
    "#shallow nnf\n",
    "'''\n",
    "in this cell,firstly, train, validation and test datasets are sliced in each loop. then shallow NNf outputs the best stocks with \n",
    "full replication and then we use the specific stocks to train the model again and get the optimal weights (each loop)\n",
    "then best model will be chosen. Also RMSE, Mean and volatility of all models and then the best model is printed.\n",
    "'''\n",
    "shallow_nnf_valid_rmse_list = []\n",
    "shallow_nnf_test_results = []\n",
    "shallow_nnf_test_plot = [] # storing the shallow model test data return for plotting later on\n",
    "\n",
    "for i in range(int(24/rbp)):\n",
    "    df_reduce = df.copy()\n",
    "    \n",
    "    x_train = data_process(date_slicer(df, '2014-07-01', 36, i*rbp))\n",
    "    print(\"x_train.shape\")\n",
    "    print(x_train.shape)\n",
    "    \n",
    "    y_train = data_process(date_slicer(df_sp, '2014-07-01', 36, i*rbp))\n",
    "    print(\"y_train.shape\")\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    x_valid = data_process(date_slicer(df, '2017-07-01', 6, i*rbp))\n",
    "    print(\"x_valid.shape\")\n",
    "    print(x_valid.shape)\n",
    "    \n",
    "    y_valid = data_process(date_slicer(df_sp, '2017-07-01', 6, i*rbp))\n",
    "    print(\"y_valid.shape\")\n",
    "    print(y_valid.shape)\n",
    "    \n",
    "    x_test = data_process(date_slicer(df, '2018-01-01', 1, i*rbp))\n",
    "    print(\"x_test.shape\")\n",
    "    print(x_test.shape)\n",
    "    y_test = data_process(date_slicer(df_sp, '2018-01-01', 1, i*rbp))\n",
    "    print(\"y_test.shape\")\n",
    "    print(y_test.shape)\n",
    "\n",
    "    \n",
    "    weights = train_shallow_nnf(x_train, y_train, i*rbp)\n",
    "    \n",
    "    print(\"weights.shape:\")\n",
    "    print(weights.shape)\n",
    "    \n",
    "    x_train, x_valid, x_test, out_index = partial(x_train, x_valid, x_test, weights, stocks_index, num = partial_num)\n",
    "    \n",
    "    df_reduce = df_reduce.drop(out_index, axis=1)\n",
    "    train_shallow_nnf_partial(x_train, y_train, i*rbp)\n",
    "    shallow_nnf_valid_rmse_list.append(valid_fun(x_valid, i*rbp, shallow_NNF_partial))\n",
    "    shallow_nnf_test_results.append(test_fun(x_test, i*rbp, shallow_NNF_partial))\n",
    "    portfolio_return(df_reduce, x_test, shallow_NNF_partial, i, shallow_nnf_test_plot)\n",
    "    shallow_NNF.reset_parameters()\n",
    "    shallow_NNF_partial.reset_parameters()\n",
    "\n",
    "# print(f'\\nMin Valid RMSE is: {min(valid_rmse_list)} for model i = {(deep_best_result_index)+1}')\n",
    "print('Selected Model Test Results for model i =', (deep_best_result_index)+1, 'are: ')\n",
    "print('RMSE =', shallow_nnf_test_results[(deep_best_result_index)]['RMSE'])\n",
    "print('MEAN =', shallow_nnf_test_results[(deep_best_result_index)]['MEAN'])\n",
    "print('VOL =', shallow_nnf_test_results[(deep_best_result_index)]['VOL'])\n",
    "\n",
    "shallow_nnf_test_plot = np.array(shallow_nnf_test_plot).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "72a5606bcafec1593511b6d198bb0982fb8ea54acb1913d581966686ae52246b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
